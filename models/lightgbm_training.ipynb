{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96846f28",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04167ffe",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcec0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from typing import Iterator, Tuple\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c977f04",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a89b724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placa</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>LINEA</th>\n",
       "      <th>DIR</th>\n",
       "      <th>proxima_est_teorica</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>dist_a_prox_m</th>\n",
       "      <th>dist_estacion_m</th>\n",
       "      <th>vel_mps</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_m</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>dwell_same_xy_s</th>\n",
       "      <th>is_no_progress</th>\n",
       "      <th>progress_event</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_peak</th>\n",
       "      <th>ETA_proxima_est_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:39:59</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>305.589294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.906372</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:40:51</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>300.037140</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>241.114578</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:41:22</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>282.313660</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>222.698257</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:42:22</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>236.359512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>177.069855</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:43:22</td>\n",
       "      <td>2249.548340</td>\n",
       "      <td>201.316711</td>\n",
       "      <td>10.833334</td>\n",
       "      <td>...</td>\n",
       "      <td>6.144639</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Placa trip_id block_id     LINEA  DIR proxima_est_teorica  \\\n",
       "0    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "1    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "2    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "3    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "4    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "\n",
       "                Fecha  dist_a_prox_m  dist_estacion_m    vel_mps  ...  \\\n",
       "0 2024-02-07 06:39:59    2507.478516       305.589294   0.000000  ...   \n",
       "1 2024-02-07 06:40:51    2507.478516       300.037140   2.222222  ...   \n",
       "2 2024-02-07 06:41:22    2507.478516       282.313660   4.166667  ...   \n",
       "3 2024-02-07 06:42:22    2507.478516       236.359512   0.000000  ...   \n",
       "4 2024-02-07 06:43:22    2249.548340       201.316711  10.833334  ...   \n",
       "\n",
       "       dist_m  time_diff  dwell_same_xy_s  is_no_progress  progress_event  \\\n",
       "0  246.906372       60.0              0.0               0               0   \n",
       "1  241.114578       52.0              0.0               0               1   \n",
       "2  222.698257       31.0              0.0               0               1   \n",
       "3  177.069855       60.0              0.0               0               1   \n",
       "4    6.144639       60.0              0.0               0               1   \n",
       "\n",
       "   hour  dow  is_weekend  is_peak  ETA_proxima_est_s  \n",
       "0     6    2           0        1              462.0  \n",
       "1     6    2           0        1              410.0  \n",
       "2     6    2           0        1              379.0  \n",
       "3     6    2           0        1              319.0  \n",
       "4     6    2           0        1              259.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener .parquet de datos muestreados\n",
    "SAMPLE_PATH = 'D:/2025/UVG/Tesis/repos/backend/features_sampled_without_idle_rows/sample_features.parquet'\n",
    "\n",
    "data = pd.read_parquet(SAMPLE_PATH)\n",
    "\n",
    "# Renombrar columna \"Altitud (m)\" a \"Altitud\"\n",
    "data = data.rename(columns={\"Altitud (m)\": \"Altitud\"})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34bdc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos\n",
    "\n",
    "# Columnas iniciales\n",
    "str_cols = [\"Placa\",\"trip_id\",\"block_id\",\"LINEA\",\"DIR\",\"proxima_est_teorica\"]\n",
    "dt_cols  = [\"Fecha\"]\n",
    "float_cols = [\n",
    "    \"dist_a_prox_m\",\"dist_estacion_m\",\"vel_mps\",\"Altitud\",\"s_m\",\"dist_m\",\n",
    "    \"time_diff\",\"dwell_same_xy_s\",\"ETA_proxima_est_s\"\n",
    "]\n",
    "int_cols = [\"hour\",\"dow\"]\n",
    "boolish_cols = [\"is_no_progress\",\"progress_event\",\"is_weekend\",\"is_peak\"]\n",
    "\n",
    "# Convertir tipos\n",
    "for c in str_cols:\n",
    "    data[c] = data[c].astype(\"category\")\n",
    "for c in dt_cols:\n",
    "    data[c] = pd.to_datetime(data[c])\n",
    "for c in float_cols:\n",
    "    data[c] = data[c].astype(\"float32\")\n",
    "for c in int_cols:\n",
    "    data[c] = data[c].astype(\"int32\")\n",
    "for c in boolish_cols:\n",
    "    data[c] = data[c].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd74ce5",
   "metadata": {},
   "source": [
    "### Train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35b8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "dev_df = df[df[\"Fecha\"] < \"2025-04-01\"]   # TODO lo anterior a abril 2025\n",
    "test_df = df[df[\"Fecha\"] >= \"2025-04-01\"] # TODO abril 2025 en adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f326362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_based_time_cv_full(\n",
    "    df: pd.DataFrame,\n",
    "    day_col: str = \"Fecha\",\n",
    "    min_train_days: int = 30,   # entrena al menos 30 días antes del 1er fold\n",
    "    valid_days: int = 2,        # ventana de validación por fold\n",
    "    step_days: int = 7,         # cuánto avanzas la ventana por fold (stride)\n",
    "    embargo_days: int = 0,      # buffer entre train y valid (opcional)\n",
    "    max_splits = None,  # None = hasta agotar el timeline\n",
    ") -> Iterator[Tuple[np.ndarray, np.ndarray]]:\n",
    "    d = df.copy()\n",
    "    d[\"__day__\"] = pd.to_datetime(d[day_col]).dt.normalize()\n",
    "    unique_days = np.array(sorted(d[\"__day__\"].unique()))\n",
    "    total_days = len(unique_days)\n",
    "\n",
    "    start_valid = min_train_days + embargo_days\n",
    "    splits = 0\n",
    "    while start_valid + valid_days <= total_days:\n",
    "        train_last = start_valid - embargo_days - 1\n",
    "        valid_start = start_valid\n",
    "        valid_end   = start_valid + valid_days  # exclusivo\n",
    "\n",
    "        train_days = set(unique_days[:train_last+1])\n",
    "        valid_days_set = set(unique_days[valid_start:valid_end])\n",
    "\n",
    "        mask_train = d[\"__day__\"].isin(train_days).values\n",
    "        mask_valid = d[\"__day__\"].isin(valid_days_set).values\n",
    "\n",
    "        tr_idx = df.index[mask_train].values\n",
    "        va_idx = df.index[mask_valid].values\n",
    "\n",
    "        yield np.sort(tr_idx), np.sort(va_idx)\n",
    "\n",
    "        splits += 1\n",
    "        if (max_splits is not None) and (splits >= max_splits):\n",
    "            break\n",
    "        start_valid += step_days  # avanza la ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_splits(df, splits, day_col=\"Fecha\", key_cols=(\"Placa\",\"trip_id\")):\n",
    "    df = df.copy()\n",
    "    df[\"__day__\"] = pd.to_datetime(df[day_col]).dt.normalize()\n",
    "    df[\"__trip_key__\"] = list(zip(*[df[c].astype(str) for c in key_cols]))  # (Placa, trip_id)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(splits, 1):\n",
    "        tr_days = df.loc[tr_idx, \"__day__\"].unique()\n",
    "        va_days = df.loc[va_idx, \"__day__\"].unique()\n",
    "\n",
    "        print(f\"\\nFold {i}\")\n",
    "        print(\"  Train days:\", tr_days.min(), \"→\", tr_days.max(), f\"({len(tr_days)} días, {len(tr_idx):,} filas)\")\n",
    "        print(\"  Valid days:\", va_days.min(), \"→\", va_days.max(), f\"({len(va_days)} días, {len(va_idx):,} filas)\")\n",
    "        day_overlap = set(tr_days) & set(va_days)\n",
    "        print(\"  Day overlap? \", \"YES\" if day_overlap else \"NO\")\n",
    "\n",
    "        tr_keys = set(df.loc[tr_idx, \"__trip_key__\"].unique())\n",
    "        va_keys = set(df.loc[va_idx, \"__trip_key__\"].unique())\n",
    "        key_overlap = tr_keys & va_keys\n",
    "        print(\"  Trip overlap (Placa,trip_id)? \", f\"YES ({len(key_overlap)})\" if key_overlap else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f313d142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-01-30 00:00:00 (30 días, 332,231 filas)\n",
      "  Valid days: 2024-01-31 00:00:00 → 2024-02-04 00:00:00 (5 días, 67,868 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 2\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-02-29 00:00:00 (60 días, 691,367 filas)\n",
      "  Valid days: 2024-03-01 00:00:00 → 2024-03-05 00:00:00 (5 días, 55,245 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 3\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-03-30 00:00:00 (90 días, 980,057 filas)\n",
      "  Valid days: 2024-03-31 00:00:00 → 2024-04-04 00:00:00 (5 días, 56,996 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 4\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-04-29 00:00:00 (120 días, 1,302,882 filas)\n",
      "  Valid days: 2024-04-30 00:00:00 → 2024-05-04 00:00:00 (5 días, 54,200 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 5\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-05-29 00:00:00 (150 días, 1,648,828 filas)\n",
      "  Valid days: 2024-05-30 00:00:00 → 2024-06-03 00:00:00 (5 días, 59,336 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 6\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-06-28 00:00:00 (180 días, 2,000,861 filas)\n",
      "  Valid days: 2024-06-29 00:00:00 → 2024-07-03 00:00:00 (5 días, 42,713 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 7\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-07-28 00:00:00 (210 días, 2,313,556 filas)\n",
      "  Valid days: 2024-07-29 00:00:00 → 2024-08-02 00:00:00 (5 días, 56,086 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 8\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-08-27 00:00:00 (240 días, 2,581,878 filas)\n",
      "  Valid days: 2024-08-28 00:00:00 → 2024-09-01 00:00:00 (5 días, 53,058 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 9\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-09-26 00:00:00 (270 días, 2,871,423 filas)\n",
      "  Valid days: 2024-09-27 00:00:00 → 2024-10-01 00:00:00 (5 días, 52,752 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 10\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-10-26 00:00:00 (300 días, 3,191,300 filas)\n",
      "  Valid days: 2024-10-27 00:00:00 → 2024-10-31 00:00:00 (5 días, 50,538 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 11\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-11-25 00:00:00 (330 días, 3,479,487 filas)\n",
      "  Valid days: 2024-11-26 00:00:00 → 2024-11-30 00:00:00 (5 días, 46,103 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 12\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-12-25 00:00:00 (360 días, 3,789,178 filas)\n",
      "  Valid days: 2024-12-26 00:00:00 → 2024-12-30 00:00:00 (5 días, 38,191 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 13\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-01-24 00:00:00 (390 días, 4,055,062 filas)\n",
      "  Valid days: 2025-01-25 00:00:00 → 2025-01-29 00:00:00 (5 días, 46,103 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 14\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-02-23 00:00:00 (420 días, 4,355,174 filas)\n",
      "  Valid days: 2025-02-24 00:00:00 → 2025-02-28 00:00:00 (5 días, 53,120 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 15\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-03-26 00:00:00 (450 días, 4,623,314 filas)\n",
      "  Valid days: 2025-03-27 00:00:00 → 2025-03-31 00:00:00 (5 días, 42,237 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n"
     ]
    }
   ],
   "source": [
    "splits = list(day_based_time_cv_full(\n",
    "    dev_df,\n",
    "    day_col=\"Fecha\",\n",
    "    min_train_days=30,\n",
    "    valid_days=5,\n",
    "    step_days=30,        # un fold por dos meses\n",
    "    embargo_days=0,     # buffer de 0 días\n",
    "    max_splits=None     # None = hasta el final del timeline\n",
    "))\n",
    "\n",
    "\n",
    "# Verificar los splits\n",
    "summarize_splits(dev_df, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25da36f",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c840662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características y objetivo\n",
    "\n",
    "categorical_features = [\"LINEA\",\"DIR\",\"proxima_est_teorica\"]\n",
    "numeric_features = [\n",
    "    \"dist_a_prox_m\",\"dist_estacion_m\",\n",
    "    \"vel_mps\",\"Altitud\",\"s_m\",\"dist_m\",\n",
    "    \"time_diff\",\"dwell_same_xy_s\",\"hour\",\"dow\",\n",
    "    \"is_no_progress\",\"progress_event\",\"is_weekend\",\"is_peak\"\n",
    "]\n",
    "\n",
    "feature_cols = categorical_features + numeric_features\n",
    "target_col = \"ETA_proxima_est_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f886946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6640f",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dev_df[feature_cols]\n",
    "y_train = dev_df[target_col]\n",
    "X_valid = test_df[feature_cols]\n",
    "y_valid = test_df[target_col]\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a310239",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     19\u001b[0m     params,\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mtrain_data\u001b[49m,\n\u001b[0;32m     21\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[train_data, valid_data],\n\u001b[0;32m     22\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     23\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m,\n\u001b[0;32m     24\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     25\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     26\u001b[0m         lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m),\n\u001b[0;32m     27\u001b[0m     ]\n\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Definir parámetros\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"mae\",\"rmse\"],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"min_data_in_leaf\": 200,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"max_bin\": 255,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \"lambda_l2\": 0.1,\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "# Entrenar modelo\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\",\"valid\"],\n",
    "    num_boost_round=3000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=300, verbose=True),\n",
    "        lgb.log_evaluation(period=100),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f28e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linea: Linea_12, Siguiente estación: CENMA, Predicción: 328.60, Real: 600.00\n",
      "Linea: Linea_12, Siguiente estación: CENMA, Predicción: 589.14, Real: 300.00\n",
      "Linea: Linea_12, Siguiente estación: TRÉBOL DIRECCIÓN CENTRO, Predicción: 382.93, Real: 600.00\n",
      "Linea: Linea_12, Siguiente estación: TRÉBOL DIRECCIÓN CENTRO, Predicción: 584.19, Real: 300.00\n",
      "Linea: Linea_12, Siguiente estación: LAS CHARCAS DIRECCIÓN CENMA, Predicción: 362.56, Real: 300.00\n"
     ]
    }
   ],
   "source": [
    "# Realizar una predicción de prueba\n",
    "for i in range(5):\n",
    "    print(f'Linea: {X_test[\"LINEA\"].iloc[i]}, Siguiente estación: {X_test[\"proxima_est_teorica\"].iloc[i]}, Predicción: {y_pred[i]:.2f}, Real: {y_test.iloc[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f681c50",
   "metadata": {},
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a666e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 125.70 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MAE: {mae:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b743051a",
   "metadata": {},
   "source": [
    "RSME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1468171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 351.43 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9fe381",
   "metadata": {},
   "source": [
    "R2 - Coeficiente de determinación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb1e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1413630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo Zamora\\AppData\\Local\\Temp\\ipykernel_28408\\508538639.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  line_stats = by_line.groupby(\"LINEA\")[\"abs_err\"].agg([\"mean\",\"median\",\"count\"]).sort_values(\"mean\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mean      median    count\n",
      "LINEA                                      \n",
      "Linea_1      61.126804   32.019461   577277\n",
      "Linea_13-A   94.980999   40.152969   371452\n",
      "Linea_6     104.827698   40.983663   939870\n",
      "Linea_12    105.028820   28.941709  1772805\n",
      "Linea_2     112.369283   49.643148   239408\n",
      "Linea_7     152.022106   58.874034    37876\n",
      "Linea_18-A  167.657788   79.098083   806776\n",
      "Linea_18-B  181.953693   87.914202   170019\n",
      "Linea_13-B  212.699097  103.227633    13042\n"
     ]
    }
   ],
   "source": [
    "by_line = data.copy()\n",
    "by_line[\"pred\"] = model.predict(X, num_iteration=model.best_iteration)\n",
    "by_line[\"abs_err\"] = np.abs(by_line[\"pred\"] - by_line[\"ETA_proxima_est_s\"])\n",
    "line_stats = by_line.groupby(\"LINEA\", observed=False)[\"abs_err\"].agg([\"mean\",\"median\",\"count\"]).sort_values(\"mean\")\n",
    "print('MAE por línea:')\n",
    "print(line_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbafb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x29567e01910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Guardar modelo\n",
    "model.save_model(\"lightgbm_baseline_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f310b49",
   "metadata": {},
   "source": [
    "Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e344efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para métricas\n",
    "\n",
    "SLA_THRESH = [60, 120, 180]    # segundos\n",
    "\n",
    "def compute_metrics(y_true, y_pred, sla_thresh=SLA_THRESH):\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(root_mean_squared_error(y_true, y_pred))\n",
    "    abs_err = np.abs(y_pred - y_true)\n",
    "    sla = {f\"sla_le_{t}s\": float((abs_err <= t).mean()) for t in sla_thresh}\n",
    "    return {\"mae\": mae, \"rmse\": rmse, **sla}\n",
    "\n",
    "\n",
    "# Definir parámetros\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"mae\",\"rmse\"],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"min_data_in_leaf\": 200,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"max_bin\": 255,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \"lambda_l2\": 0.1,\n",
    "    \"verbose\": 1,\n",
    "    \"seed\": SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b543ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2108\n",
      "[LightGBM] [Info] Number of data points in the train set: 332231, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 309.223140\n",
      "\n",
      "=== Fold 2 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2061\n",
      "[LightGBM] [Info] Number of data points in the train set: 691367, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 306.681998\n",
      "\n",
      "=== Fold 3 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2091\n",
      "[LightGBM] [Info] Number of data points in the train set: 980057, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 302.871706\n",
      "\n",
      "=== Fold 4 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2097\n",
      "[LightGBM] [Info] Number of data points in the train set: 1302882, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 303.160862\n",
      "\n",
      "=== Fold 5 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2084\n",
      "[LightGBM] [Info] Number of data points in the train set: 1648828, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 301.657169\n",
      "\n",
      "=== Fold 6 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000861, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 301.822240\n",
      "\n",
      "=== Fold 7 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2101\n",
      "[LightGBM] [Info] Number of data points in the train set: 2313556, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 303.245529\n",
      "\n",
      "=== Fold 8 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2099\n",
      "[LightGBM] [Info] Number of data points in the train set: 2581878, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 306.105069\n",
      "\n",
      "=== Fold 9 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 2871423, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 309.097239\n",
      "\n",
      "=== Fold 10 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.148196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 3191300, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 309.981903\n",
      "\n",
      "=== Fold 11 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2094\n",
      "[LightGBM] [Info] Number of data points in the train set: 3479487, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 308.069363\n",
      "\n",
      "=== Fold 12 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.166977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2117\n",
      "[LightGBM] [Info] Number of data points in the train set: 3789178, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 308.534139\n",
      "\n",
      "=== Fold 13 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2112\n",
      "[LightGBM] [Info] Number of data points in the train set: 4055062, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 307.658761\n",
      "\n",
      "=== Fold 14 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.182895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2116\n",
      "[LightGBM] [Info] Number of data points in the train set: 4355174, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 308.250458\n",
      "\n",
      "=== Fold 15 ===\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.186009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2110\n",
      "[LightGBM] [Info] Number of data points in the train set: 4623314, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 308.826575\n"
     ]
    }
   ],
   "source": [
    "fold_results = []\n",
    "models = []\n",
    "best_iters = []\n",
    "fi_gain_list = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(splits, 1):\n",
    "    \n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    X_train = dev_df.loc[tr_idx, feature_cols]\n",
    "    y_train = dev_df.loc[tr_idx, target_col]\n",
    "    X_valid = dev_df.loc[va_idx, feature_cols]\n",
    "    y_valid = dev_df.loc[va_idx, target_col]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features, free_raw_data=True)\n",
    "    lgb_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=categorical_features, free_raw_data=True)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        valid_sets=[lgb_valid],\n",
    "        valid_names=[f\"valid{fold}\"],\n",
    "        num_boost_round=3000,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=300, verbose=False)]\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    metrics = compute_metrics(y_valid.values, y_pred, SLA_THRESH)\n",
    "    metrics[\"fold\"] = fold\n",
    "    metrics[\"best_iter\"] = int(model.best_iteration)\n",
    "    fold_results.append(metrics)\n",
    "    best_iters.append(model.best_iteration)\n",
    "    models.append(model)\n",
    "\n",
    "    # importancias (gain)\n",
    "    fi_gain = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"gain\": model.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": fold,\n",
    "    })\n",
    "    fi_gain_list.append(fi_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "859e81e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas por fold ===\n",
      "             mae        rmse  sla_le_60s  sla_le_120s  sla_le_180s  best_iter\n",
      "fold                                                                         \n",
      "1     123.375711  304.764493    0.595126     0.761360     0.835814        297\n",
      "2     105.208006  272.522437    0.628238     0.796597     0.867970        253\n",
      "3     118.302275  370.476806    0.649625     0.804513     0.865798        979\n",
      "4     103.972052  284.459356    0.640867     0.802768     0.872251       1383\n",
      "5     102.157242  270.759024    0.643892     0.803880     0.872084       2165\n",
      "6     107.985908  298.637310    0.615176     0.785522     0.862946       1220\n",
      "7     136.089878  352.630542    0.592287     0.754288     0.827319       1634\n",
      "8     112.733356  292.282094    0.613649     0.784575     0.858344        595\n",
      "9     125.435332  325.330707    0.610972     0.771686     0.843115        860\n",
      "10    128.783631  331.325955    0.586054     0.754699     0.834402        264\n",
      "11    130.325481  321.783620    0.559833     0.736069     0.821291        689\n",
      "12    149.909096  434.074804    0.561991     0.738472     0.825273        108\n",
      "13    114.662095  343.878022    0.642366     0.799189     0.865453        920\n",
      "14    137.704092  346.344194    0.580102     0.748061     0.825791        933\n",
      "15    113.153026  299.724162    0.615101     0.785591     0.858229        333\n",
      "\n",
      "=== Promedio CV ± std ===\n",
      "             mae        rmse  sla_le_60s  sla_le_120s  sla_le_180s   best_iter\n",
      "mean  120.653145  323.266235    0.609019     0.775151     0.849072  842.200000\n",
      "std    14.027120   42.844866    0.029189     0.024576     0.019113  579.833745\n",
      "\n",
      "Iteraciones promedio (best_iteration): 842\n",
      "\n",
      "Top-20 features por gain promedio:\n",
      "feature\n",
      "dist_m                 9.970863e+11\n",
      "proxima_est_teorica    7.443105e+11\n",
      "dist_a_prox_m          5.395383e+11\n",
      "hour                   3.630554e+11\n",
      "s_m                    3.308570e+11\n",
      "dist_estacion_m        2.601003e+11\n",
      "Altitud                1.489033e+11\n",
      "vel_mps                1.196891e+11\n",
      "dow                    8.737637e+10\n",
      "LINEA                  8.122230e+10\n",
      "dwell_same_xy_s        6.917117e+10\n",
      "time_diff              4.199150e+10\n",
      "is_peak                4.056561e+10\n",
      "is_weekend             9.704937e+09\n",
      "DIR                    8.774777e+09\n",
      "progress_event         7.150075e+09\n",
      "is_no_progress         2.159386e+09\n",
      "Name: gain, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(fold_results).set_index(\"fold\")\n",
    "print(\"\\n=== Métricas por fold ===\")\n",
    "print(cv_df)\n",
    "\n",
    "print(\"\\n=== Promedio CV ± std ===\")\n",
    "summary = cv_df.agg([\"mean\",\"std\"])\n",
    "print(summary)\n",
    "\n",
    "avg_best_iter = int(np.mean(best_iters))\n",
    "print(f\"\\nIteraciones promedio (best_iteration): {avg_best_iter}\")\n",
    "\n",
    "fi_gain_all = pd.concat(fi_gain_list, ignore_index=True)\n",
    "fi_gain_mean = fi_gain_all.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False)\n",
    "print(\"\\nTop-20 features por gain promedio:\")\n",
    "print(fi_gain_mean.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db62405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelos entrenados por fold\n",
    "import os\n",
    "\n",
    "model_dir = \"D:/2025/UVG/Tesis/repos/backend/models/lightgbm/cross_validation_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for fold, model in enumerate(models, 1):\n",
    "    model.save_model(f\"{model_dir}/lgb_model_fold{fold}.txt\")\n",
    "    \n",
    "# Guardar métricas CV\n",
    "cv_df.to_csv(f\"{model_dir}/cv_metrics.csv\")\n",
    "# Guardar importancias\n",
    "fi_gain_all.to_csv(f\"{model_dir}/cv_feature_importances_gain.csv\", index=False)\n",
    "\n",
    "# Guardar parámetros usados\n",
    "import json\n",
    "with open(f\"{model_dir}/lgb_params.json\", \"w\") as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab19fa6",
   "metadata": {},
   "source": [
    "Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e0c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.183048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 4665551, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 308.566816\n"
     ]
    }
   ],
   "source": [
    "final_rounds = int(np.median(best_iters))\n",
    "\n",
    "lgb_train_full = lgb.Dataset(dev_df[feature_cols], label=dev_df[target_col], categorical_feature=categorical_features)\n",
    "\n",
    "final_model = lgb.train(\n",
    "    {**params, \"metric\": []},\n",
    "    lgb_train_full,\n",
    "    num_boost_round=final_rounds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5743a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas en set de prueba (LightGBM final) ===\n",
      "mae: 134.09 s\n",
      "rmse: 381.64 s\n",
      "sla_le_60s: 59.85%\n",
      "sla_le_120s: 76.34%\n",
      "sla_le_180s: 83.85%\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "# Métricas en set de prueba\n",
    "y_test_pred = final_model.predict(test_df[feature_cols], num_iteration=final_model.best_iteration)\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "test_metrics = compute_metrics(y_test.values, y_test_pred, SLA_THRESH)\n",
    "print(\"\\n=== Métricas en set de prueba (LightGBM final) ===\")\n",
    "\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v*100:.2f}%\" if k.startswith(\"sla_\") else f\"{k}: {v:.2f} s\")\n",
    "    \n",
    "# Guardar modelo final\n",
    "final_dir = \"D:/2025/UVG/Tesis/repos/backend/models/lightgbm/final\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "final_model.save_model(f\"{final_dir}/lgb_final_model.txt\")\n",
    "\n",
    "# Guardar métricas del set de prueba\n",
    "with open(f\"{final_dir}/test_metrics.json\", \"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in test_metrics.items()}, f, indent=2)\n",
    "    \n",
    "# Guardar parámetros y metadatos del modelo final\n",
    "\n",
    "final_meta = {\n",
    "    \"final_rounds\": final_rounds,\n",
    "    \"params\": params,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"target_col\": target_col,\n",
    "}\n",
    "\n",
    "with open(f\"{final_dir}/final_meta.json\", \"w\") as f:\n",
    "    json.dump(final_meta, f, indent=4)\n",
    "    \n",
    "pd.DataFrame({\n",
    "    \"Fecha\": test_df[\"Fecha\"].values,\n",
    "    \"Placa\": test_df[\"Placa\"].astype(str).values if \"Placa\" in test_df.columns else None,\n",
    "    \"ETA_true\": test_df[target_col].values,\n",
    "    \"ETA_pred\": y_test_pred,\n",
    "    \"abs_error\": np.abs(test_df[target_col].values - y_test_pred)\n",
    "}).to_csv(f\"{final_dir}/test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c296a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST por LINEA,DIR ===\n",
      "         LINEA       DIR         MAE        RMSE   SLA<=60  SLA<=120  \\\n",
      "5     Linea_12    VUELTA   37.241484   73.890660  0.837830  0.960785   \n",
      "0      Linea_1  CIRCULAR   66.873459  179.296865  0.721675  0.884076   \n",
      "8   Linea_13-A    VUELTA   84.555965  214.185734  0.639465  0.822200   \n",
      "16  Linea_18-B       IDA  112.268444  215.568132  0.585340  0.759561   \n",
      "23     Linea_6    VUELTA  114.803768  321.494400  0.643081  0.798885   \n",
      "19     Linea_2       IDA  119.450127  359.277722  0.513148  0.726772   \n",
      "7   Linea_13-A       IDA  130.956218  402.555213  0.548346  0.773098   \n",
      "26     Linea_7    VUELTA  132.455665  367.345494  0.598203  0.774069   \n",
      "22     Linea_6       IDA  139.513441  371.884852  0.565573  0.746143   \n",
      "20     Linea_2    VUELTA  165.661599  547.476555  0.656984  0.800239   \n",
      "\n",
      "    SLA<=180        n  \n",
      "5   0.985283  42739.0  \n",
      "0   0.932820  33522.0  \n",
      "8   0.900586  13982.0  \n",
      "16  0.831445   2824.0  \n",
      "23  0.860219  15603.0  \n",
      "19  0.852742   7986.0  \n",
      "7   0.867784   6981.0  \n",
      "26  0.857510    779.0  \n",
      "22  0.838741  27031.0  \n",
      "20  0.853561   2513.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo Zamora\\AppData\\Local\\Temp\\ipykernel_20020\\3329905506.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agg = tmp.groupby(by).apply(\n"
     ]
    }
   ],
   "source": [
    "# Desglose por línea\n",
    "def group_report(df, y_true, y_pred, by=[\"LINEA\",\"DIR\"]):\n",
    "    tmp = df.copy()\n",
    "    tmp[\"y_true\"] = y_true\n",
    "    tmp[\"y_pred\"] = y_pred\n",
    "    tmp[\"abs_err\"] = (y_true - y_pred).abs()\n",
    "    agg = tmp.groupby(by).apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"MAE\": g[\"abs_err\"].mean(),\n",
    "            \"RMSE\": (( (g[\"y_true\"]-g[\"y_pred\"])**2 ).mean())**0.5,\n",
    "            \"SLA<=60\": (g[\"abs_err\"]<=60).mean(),\n",
    "            \"SLA<=120\": (g[\"abs_err\"]<=120).mean(),\n",
    "            \"SLA<=180\": (g[\"abs_err\"]<=180).mean(),\n",
    "            \"n\": len(g)\n",
    "        })\n",
    "    ).reset_index()\n",
    "    return agg\n",
    "\n",
    "seg = group_report(test_df, test_df[target_col], y_test_pred, by=[\"LINEA\",\"DIR\"])\n",
    "print(\"\\n=== TEST por LINEA,DIR ===\")\n",
    "print(seg.sort_values(\"MAE\").head(10))\n",
    "seg.to_csv(f\"{final_dir}/test_segment_metrics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
