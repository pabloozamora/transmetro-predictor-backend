{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0bc783",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bb49a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d6dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from typing import Iterator, Tuple\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbe68c",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39367fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placa</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>LINEA</th>\n",
       "      <th>DIR</th>\n",
       "      <th>proxima_est_teorica</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>dist_a_prox_m</th>\n",
       "      <th>dist_estacion_m</th>\n",
       "      <th>vel_mps</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_m</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>dwell_same_xy_s</th>\n",
       "      <th>is_no_progress</th>\n",
       "      <th>progress_event</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_peak</th>\n",
       "      <th>ETA_proxima_est_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:39:59</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>305.589294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>246.906372</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:40:51</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>300.037140</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>241.114578</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:41:22</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>282.313660</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>222.698257</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:42:22</td>\n",
       "      <td>2507.478516</td>\n",
       "      <td>236.359512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>177.069855</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Linea_12</td>\n",
       "      <td>IDA</td>\n",
       "      <td>MONTE MARÍA</td>\n",
       "      <td>2024-02-07 06:43:22</td>\n",
       "      <td>2249.548340</td>\n",
       "      <td>201.316711</td>\n",
       "      <td>10.833334</td>\n",
       "      <td>...</td>\n",
       "      <td>6.144639</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Placa trip_id block_id     LINEA  DIR proxima_est_teorica  \\\n",
       "0    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "1    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "2    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "3    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "4    49       7        1  Linea_12  IDA         MONTE MARÍA   \n",
       "\n",
       "                Fecha  dist_a_prox_m  dist_estacion_m    vel_mps  ...  \\\n",
       "0 2024-02-07 06:39:59    2507.478516       305.589294   0.000000  ...   \n",
       "1 2024-02-07 06:40:51    2507.478516       300.037140   2.222222  ...   \n",
       "2 2024-02-07 06:41:22    2507.478516       282.313660   4.166667  ...   \n",
       "3 2024-02-07 06:42:22    2507.478516       236.359512   0.000000  ...   \n",
       "4 2024-02-07 06:43:22    2249.548340       201.316711  10.833334  ...   \n",
       "\n",
       "       dist_m  time_diff  dwell_same_xy_s  is_no_progress  progress_event  \\\n",
       "0  246.906372       60.0              0.0               0               0   \n",
       "1  241.114578       52.0              0.0               0               1   \n",
       "2  222.698257       31.0              0.0               0               1   \n",
       "3  177.069855       60.0              0.0               0               1   \n",
       "4    6.144639       60.0              0.0               0               1   \n",
       "\n",
       "   hour  dow  is_weekend  is_peak  ETA_proxima_est_s  \n",
       "0     6    2           0        1              462.0  \n",
       "1     6    2           0        1              410.0  \n",
       "2     6    2           0        1              379.0  \n",
       "3     6    2           0        1              319.0  \n",
       "4     6    2           0        1              259.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener .parquet de datos muestreados\n",
    "SAMPLE_PATH = 'D:/2025/UVG/Tesis/repos/backend/features_sampled_without_idle_rows/sample_features.parquet'\n",
    "\n",
    "data = pd.read_parquet(SAMPLE_PATH)\n",
    "\n",
    "# Renombrar columna \"Altitud (m)\" a \"Altitud\"\n",
    "data = data.rename(columns={\"Altitud (m)\": \"Altitud\"})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos\n",
    "\n",
    "# Columnas iniciales\n",
    "str_cols = [\"Placa\",\"trip_id\",\"block_id\",\"LINEA\",\"DIR\",\"proxima_est_teorica\"]\n",
    "dt_cols  = [\"Fecha\"]\n",
    "float_cols = [\n",
    "    \"dist_a_prox_m\",\"dist_estacion_m\",\"vel_mps\",\"Altitud\",\"s_m\",\"dist_m\",\n",
    "    \"time_diff\",\"dwell_same_xy_s\",\"ETA_proxima_est_s\"\n",
    "]\n",
    "int_cols = [\"hour\",\"dow\"]\n",
    "boolish_cols = [\"is_no_progress\",\"progress_event\",\"is_weekend\",\"is_peak\"]\n",
    "\n",
    "# Convertir tipos\n",
    "for c in str_cols: # Convertir a string de Python no a StringDtype de pandas\n",
    "    data[c] = data[c].cat.rename_categories(lambda x: str(x))\n",
    "for c in dt_cols:\n",
    "    data[c] = pd.to_datetime(data[c])\n",
    "for c in float_cols:\n",
    "    data[c] = data[c].astype(\"float32\")\n",
    "for c in int_cols:\n",
    "    data[c] = data[c].astype(\"int32\")\n",
    "for c in boolish_cols:\n",
    "    data[c] = data[c].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38c2c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Placa                        category\n",
       "trip_id                      category\n",
       "block_id                     category\n",
       "LINEA                        category\n",
       "DIR                          category\n",
       "proxima_est_teorica          category\n",
       "Fecha                  datetime64[ns]\n",
       "dist_a_prox_m                 float32\n",
       "dist_estacion_m               float32\n",
       "vel_mps                       float32\n",
       "Altitud                       float32\n",
       "s_m                           float32\n",
       "dist_m                        float32\n",
       "time_diff                     float32\n",
       "dwell_same_xy_s               float32\n",
       "is_no_progress                   bool\n",
       "progress_event                   bool\n",
       "hour                            int32\n",
       "dow                             int32\n",
       "is_weekend                       bool\n",
       "is_peak                          bool\n",
       "ETA_proxima_est_s             float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32e0b3",
   "metadata": {},
   "source": [
    "### Train / valid / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0365f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "dev_df = df[df[\"Fecha\"] < \"2025-04-01\"]   # TODO lo anterior a abril 2025\n",
    "test_df = df[df[\"Fecha\"] >= \"2025-04-01\"] # TODO abril 2025 en adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb4bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_based_time_cv_full(\n",
    "    df: pd.DataFrame,\n",
    "    day_col: str = \"Fecha\",\n",
    "    min_train_days: int = 30,   # entrena al menos 30 días antes del 1er fold\n",
    "    valid_days: int = 2,        # ventana de validación por fold\n",
    "    step_days: int = 7,         # cuánto avanzas la ventana por fold (stride)\n",
    "    embargo_days: int = 0,      # buffer entre train y valid (opcional)\n",
    "    max_splits = None,  # None = hasta agotar el timeline\n",
    ") -> Iterator[Tuple[np.ndarray, np.ndarray]]:\n",
    "    d = df.copy()\n",
    "    d[\"__day__\"] = pd.to_datetime(d[day_col]).dt.normalize()\n",
    "    unique_days = np.array(sorted(d[\"__day__\"].unique()))\n",
    "    total_days = len(unique_days)\n",
    "\n",
    "    start_valid = min_train_days + embargo_days\n",
    "    splits = 0\n",
    "    while start_valid + valid_days <= total_days:\n",
    "        train_last = start_valid - embargo_days - 1\n",
    "        valid_start = start_valid\n",
    "        valid_end   = start_valid + valid_days  # exclusivo\n",
    "\n",
    "        train_days = set(unique_days[:train_last+1])\n",
    "        valid_days_set = set(unique_days[valid_start:valid_end])\n",
    "\n",
    "        mask_train = d[\"__day__\"].isin(train_days).values\n",
    "        mask_valid = d[\"__day__\"].isin(valid_days_set).values\n",
    "\n",
    "        tr_idx = df.index[mask_train].values\n",
    "        va_idx = df.index[mask_valid].values\n",
    "\n",
    "        yield np.sort(tr_idx), np.sort(va_idx)\n",
    "\n",
    "        splits += 1\n",
    "        if (max_splits is not None) and (splits >= max_splits):\n",
    "            break\n",
    "        start_valid += step_days  # avanza la ventana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba4844f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_splits(df, splits, day_col=\"Fecha\", key_cols=(\"Placa\",\"trip_id\")):\n",
    "    df = df.copy()\n",
    "    df[\"__day__\"] = pd.to_datetime(df[day_col]).dt.normalize()\n",
    "    df[\"__trip_key__\"] = list(zip(*[df[c].astype(str) for c in key_cols]))  # (Placa, trip_id)\n",
    "\n",
    "    for i, (tr_idx, va_idx) in enumerate(splits, 1):\n",
    "        tr_days = df.loc[tr_idx, \"__day__\"].unique()\n",
    "        va_days = df.loc[va_idx, \"__day__\"].unique()\n",
    "\n",
    "        print(f\"\\nFold {i}\")\n",
    "        print(\"  Train days:\", tr_days.min(), \"→\", tr_days.max(), f\"({len(tr_days)} días, {len(tr_idx):,} filas)\")\n",
    "        print(\"  Valid days:\", va_days.min(), \"→\", va_days.max(), f\"({len(va_days)} días, {len(va_idx):,} filas)\")\n",
    "        day_overlap = set(tr_days) & set(va_days)\n",
    "        print(\"  Day overlap? \", \"YES\" if day_overlap else \"NO\")\n",
    "\n",
    "        tr_keys = set(df.loc[tr_idx, \"__trip_key__\"].unique())\n",
    "        va_keys = set(df.loc[va_idx, \"__trip_key__\"].unique())\n",
    "        key_overlap = tr_keys & va_keys\n",
    "        print(\"  Trip overlap (Placa,trip_id)? \", f\"YES ({len(key_overlap)})\" if key_overlap else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "923011cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-01-30 00:00:00 (30 días, 332,231 filas)\n",
      "  Valid days: 2024-01-31 00:00:00 → 2024-02-04 00:00:00 (5 días, 67,868 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 2\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-02-29 00:00:00 (60 días, 691,367 filas)\n",
      "  Valid days: 2024-03-01 00:00:00 → 2024-03-05 00:00:00 (5 días, 55,245 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 3\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-03-30 00:00:00 (90 días, 980,057 filas)\n",
      "  Valid days: 2024-03-31 00:00:00 → 2024-04-04 00:00:00 (5 días, 56,996 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 4\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-04-29 00:00:00 (120 días, 1,302,882 filas)\n",
      "  Valid days: 2024-04-30 00:00:00 → 2024-05-04 00:00:00 (5 días, 54,200 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 5\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-05-29 00:00:00 (150 días, 1,648,828 filas)\n",
      "  Valid days: 2024-05-30 00:00:00 → 2024-06-03 00:00:00 (5 días, 59,336 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 6\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-06-28 00:00:00 (180 días, 2,000,861 filas)\n",
      "  Valid days: 2024-06-29 00:00:00 → 2024-07-03 00:00:00 (5 días, 42,713 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 7\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-07-28 00:00:00 (210 días, 2,313,556 filas)\n",
      "  Valid days: 2024-07-29 00:00:00 → 2024-08-02 00:00:00 (5 días, 56,086 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 8\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-08-27 00:00:00 (240 días, 2,581,878 filas)\n",
      "  Valid days: 2024-08-28 00:00:00 → 2024-09-01 00:00:00 (5 días, 53,058 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 9\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-09-26 00:00:00 (270 días, 2,871,423 filas)\n",
      "  Valid days: 2024-09-27 00:00:00 → 2024-10-01 00:00:00 (5 días, 52,752 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 10\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-10-26 00:00:00 (300 días, 3,191,300 filas)\n",
      "  Valid days: 2024-10-27 00:00:00 → 2024-10-31 00:00:00 (5 días, 50,538 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 11\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-11-25 00:00:00 (330 días, 3,479,487 filas)\n",
      "  Valid days: 2024-11-26 00:00:00 → 2024-11-30 00:00:00 (5 días, 46,103 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 12\n",
      "  Train days: 2024-01-01 00:00:00 → 2024-12-25 00:00:00 (360 días, 3,789,178 filas)\n",
      "  Valid days: 2024-12-26 00:00:00 → 2024-12-30 00:00:00 (5 días, 38,191 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 13\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-01-24 00:00:00 (390 días, 4,055,062 filas)\n",
      "  Valid days: 2025-01-25 00:00:00 → 2025-01-29 00:00:00 (5 días, 46,103 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 14\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-02-23 00:00:00 (420 días, 4,355,174 filas)\n",
      "  Valid days: 2025-02-24 00:00:00 → 2025-02-28 00:00:00 (5 días, 53,120 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n",
      "\n",
      "Fold 15\n",
      "  Train days: 2024-01-01 00:00:00 → 2025-03-26 00:00:00 (450 días, 4,623,314 filas)\n",
      "  Valid days: 2025-03-27 00:00:00 → 2025-03-31 00:00:00 (5 días, 42,237 filas)\n",
      "  Day overlap?  NO\n",
      "  Trip overlap (Placa,trip_id)?  NO\n"
     ]
    }
   ],
   "source": [
    "splits = list(day_based_time_cv_full(\n",
    "    dev_df,\n",
    "    day_col=\"Fecha\",\n",
    "    min_train_days=30,\n",
    "    valid_days=5,\n",
    "    step_days=30,        # un fold por dos meses\n",
    "    embargo_days=0,     # buffer de 0 días\n",
    "    max_splits=None     # None = hasta el final del timeline\n",
    "))\n",
    "\n",
    "\n",
    "# Verificar los splits\n",
    "summarize_splits(dev_df, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1dd50e",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33978daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características y objetivo\n",
    "\n",
    "categorical_features = [\"LINEA\",\"DIR\",\"proxima_est_teorica\"]\n",
    "numeric_features = [\n",
    "    \"dist_a_prox_m\",\"dist_estacion_m\",\n",
    "    \"vel_mps\",\"Altitud\",\"s_m\",\"dist_m\",\n",
    "    \"time_diff\",\"dwell_same_xy_s\",\"hour\",\"dow\",\n",
    "    \"is_no_progress\",\"progress_event\",\"is_weekend\",\"is_peak\"\n",
    "]\n",
    "\n",
    "feature_cols = categorical_features + numeric_features\n",
    "target_col = \"ETA_proxima_est_s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb338e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153fea2",
   "metadata": {},
   "source": [
    "Validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb07bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para métricas\n",
    "\n",
    "SLA_THRESH = [60, 120, 180]    # segundos\n",
    "\n",
    "def compute_metrics(y_true, y_pred, sla_thresh=SLA_THRESH):\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(root_mean_squared_error(y_true, y_pred))\n",
    "    abs_err = np.abs(y_pred - y_true)\n",
    "    sla = {f\"sla_le_{t}s\": float((abs_err <= t).mean()) for t in sla_thresh}\n",
    "    return {\"mae\": mae, \"rmse\": rmse, **sla}\n",
    "\n",
    "\n",
    "# Definir parámetros\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": [\"mae\", \"rmse\"],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,            # ≈ num_leaves 64 (aprox capacidad)\n",
    "    \"min_child_weight\": 200,   # ~ min_data_in_leaf\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_alpha\": 0.1,\n",
    "    \"reg_lambda\": 0.1,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_bin\": 255,\n",
    "    \"random_state\": SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dfa52b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n",
      "\n",
      "=== Fold 5 ===\n",
      "\n",
      "=== Fold 6 ===\n",
      "\n",
      "=== Fold 7 ===\n",
      "\n",
      "=== Fold 8 ===\n",
      "\n",
      "=== Fold 9 ===\n",
      "\n",
      "=== Fold 10 ===\n",
      "\n",
      "=== Fold 11 ===\n",
      "\n",
      "=== Fold 12 ===\n",
      "\n",
      "=== Fold 13 ===\n",
      "\n",
      "=== Fold 14 ===\n",
      "\n",
      "=== Fold 15 ===\n"
     ]
    }
   ],
   "source": [
    "fold_results, models, best_iters, fi_gain_list = [], [], [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(splits, 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_tr = dev_df.loc[tr_idx, feature_cols].copy()\n",
    "    y_tr = dev_df.loc[tr_idx, target_col].values\n",
    "    X_va = dev_df.loc[va_idx, feature_cols].copy()\n",
    "    y_va = dev_df.loc[va_idx, target_col].values\n",
    "\n",
    "    # Asegurarse que las categorías sean Python str (evitar pandas StringDtype 'string[python]')\n",
    "    # XGBoost falla si las categorías internas usan el tipo StringDtype; convertir las categorías a str.\n",
    "    \"\"\" for df_ in (X_tr, X_va):\n",
    "        for col in categorical_features:\n",
    "            if pd.api.types.is_categorical_dtype(df_[col]):\n",
    "                df_[col] = df_[col].cat.rename_categories(lambda x: str(x)) \"\"\"\n",
    "\n",
    "    # DMatrix detecta categóricas si dtype='category' y enable_categorical=True en params\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr, enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(X_va, label=y_va, enable_categorical=True)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=3000,\n",
    "        evals=[(dvalid, f\"valid{fold}\")],\n",
    "        early_stopping_rounds=300,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Predicción usando la mejor iteración\n",
    "    best_iter = getattr(booster, \"best_iteration\", None)\n",
    "    if best_iter is None:\n",
    "        # fallback para versiones antiguas\n",
    "        y_pred = booster.predict(dvalid, ntree_limit=booster.best_ntree_limit)\n",
    "        best_iter = booster.best_ntree_limit\n",
    "    else:\n",
    "        y_pred = booster.predict(dvalid, iteration_range=(0, best_iter + 1))\n",
    "\n",
    "    metrics = compute_metrics(y_va, y_pred, SLA_THRESH)\n",
    "    metrics[\"fold\"] = fold\n",
    "    metrics[\"best_iter\"] = int(best_iter)\n",
    "    fold_results.append(metrics)\n",
    "    best_iters.append(best_iter)\n",
    "    models.append(booster)\n",
    "\n",
    "    # Importancias por gain\n",
    "    score = booster.get_score(importance_type=\"gain\")  # dict {feat: gain}\n",
    "    fi_gain = pd.DataFrame({\"feature\": list(score.keys()), \"gain\": list(score.values()), \"fold\": fold})\n",
    "    fi_gain_list.append(fi_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2a28548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas por fold (XGB) ===\n",
      "             mae        rmse  sla_le_60s  sla_le_120s  sla_le_180s  best_iter\n",
      "fold                                                                         \n",
      "1     125.265472  304.213318    0.577828     0.756822     0.833441        877\n",
      "2     107.251045  272.445496    0.615893     0.790859     0.861472        661\n",
      "3     119.949364  369.786102    0.637782     0.797705     0.862096       2999\n",
      "4     106.672066  285.865723    0.622435     0.792878     0.865351       2981\n",
      "5     105.032524  273.298615    0.630680     0.796127     0.866540       2993\n",
      "6     110.525406  301.220428    0.605015     0.781027     0.859036       2557\n",
      "7     139.488663  354.943512    0.580608     0.746300     0.820954       2978\n",
      "8     113.440384  292.463959    0.607543     0.780844     0.854932        993\n",
      "9     129.641495  328.168854    0.594461     0.762322     0.836291        757\n",
      "10    127.874504  334.459534    0.593692     0.758696     0.836875        899\n",
      "11    130.427658  320.965424    0.562219     0.735050     0.819903       1842\n",
      "12    145.027054  426.689301    0.585400     0.751565     0.831426        586\n",
      "13    115.504662  338.065125    0.640002     0.796239     0.861874       1604\n",
      "14    138.791183  347.739716    0.578012     0.742470     0.821969       2387\n",
      "15    112.429031  297.924805    0.621114     0.786656     0.858158        730\n",
      "\n",
      "=== Promedio CV ± std (XGB) ===\n",
      "             mae        rmse  sla_le_60s  sla_le_120s  sla_le_180s  \\\n",
      "mean  121.821367  323.216661    0.603512     0.771704     0.846021   \n",
      "std    13.025959   41.191823    0.024098     0.022058     0.017683   \n",
      "\n",
      "        best_iter  \n",
      "mean  1722.933333  \n",
      "std    993.940532  \n",
      "\n",
      "Iteraciones promedio (best_iteration): 1722\n",
      "\n",
      "Top-20 features por gain promedio (XGB):\n",
      "feature\n",
      "dist_m                 1.114828e+08\n",
      "dist_a_prox_m          9.679513e+07\n",
      "s_m                    8.067015e+07\n",
      "proxima_est_teorica    7.695403e+07\n",
      "LINEA                  4.211128e+07\n",
      "hour                   3.747953e+07\n",
      "is_weekend             3.625466e+07\n",
      "vel_mps                3.452856e+07\n",
      "is_peak                3.350784e+07\n",
      "DIR                    3.307371e+07\n",
      "dist_estacion_m        2.814846e+07\n",
      "Altitud                2.717859e+07\n",
      "progress_event         2.655076e+07\n",
      "dwell_same_xy_s        2.033919e+07\n",
      "dow                    1.739175e+07\n",
      "time_diff              1.375211e+07\n",
      "is_no_progress         1.131480e+07\n",
      "Name: gain, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(fold_results).set_index(\"fold\")\n",
    "print(\"\\n=== Métricas por fold (XGB) ===\")\n",
    "print(cv_df)\n",
    "print(\"\\n=== Promedio CV ± std (XGB) ===\")\n",
    "print(cv_df.agg([\"mean\",\"std\"]))\n",
    "\n",
    "avg_best_iter = int(np.mean([int(b) for b in best_iters]))\n",
    "print(f\"\\nIteraciones promedio (best_iteration): {avg_best_iter}\")\n",
    "\n",
    "fi_gain_all = pd.concat(fi_gain_list, ignore_index=True)\n",
    "fi_gain_mean = fi_gain_all.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False)\n",
    "print(\"\\nTop-20 features por gain promedio (XGB):\")\n",
    "print(fi_gain_mean.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5acb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime, platform\n",
    "\n",
    "model_dir = \"D:/2025/UVG/Tesis/repos/backend/models/xgboost/cross_validation_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# 1) Guardar boosters por fold en JSON + config\n",
    "for fold, booster in enumerate(models, 1):\n",
    "    booster.save_model(f\"{model_dir}/xgb_model_fold{fold}.json\")\n",
    "    # Booster.save_config() returns a JSON string (no args), so write it to file explicitly.\n",
    "    cfg = booster.save_config()\n",
    "    with open(f\"{model_dir}/xgb_model_fold{fold}.config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cfg)\n",
    "\n",
    "# 2) Guardar métricas y FI\n",
    "cv_df.to_csv(f\"{model_dir}/cv_metrics.csv\")\n",
    "fi_gain_all.to_csv(f\"{model_dir}/cv_feature_importances_gain.csv\", index=False)\n",
    "\n",
    "# 3) Guardar parámetros usados y metadatos\n",
    "meta = {\n",
    "    \"params\": params,\n",
    "    \"xgboost_version\": xgb.__version__,\n",
    "    \"created_at\": datetime.datetime.now().isoformat(),\n",
    "    \"python_version\": platform.python_version(),\n",
    "    \"feature_cols\": list(feature_cols),\n",
    "    \"target_col\": target_col,\n",
    "    \"splits_summary\": {\n",
    "        \"n_folds\": len(models),\n",
    "        \"notes\": \"Time-based CV (day blocks), same splits as LGBM baseline\"\n",
    "    },\n",
    "    \"best_iters\": list(map(int, best_iters)),\n",
    "    \"recommend_final_rounds\": int(np.median(best_iters))  # o int(np.mean(...)*1.05)\n",
    "}\n",
    "with open(f\"{model_dir}/manifest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# 4) Guardar esquema de dtypes (para reproducir preprocessing en inferencia)\n",
    "dtypes_info = {c: str(dev_df[c].dtype) for c in feature_cols + [target_col]}\n",
    "pd.Series(dtypes_info).to_csv(f\"{model_dir}/feature_dtypes.csv\", header=False)\n",
    "\n",
    "# 5) Guardar categorías por columna\n",
    "CATEGORICAL_COLS = [\"Placa\",\"trip_id\",\"block_id\",\"LINEA\",\"DIR\",\"proxima_est_teorica\"]\n",
    "cat_maps = {c: list(dev_df[c].astype(\"category\").cat.categories) for c in CATEGORICAL_COLS if c in dev_df.columns}\n",
    "with open(f\"{model_dir}/categorical_mappings.json\",\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cat_maps, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2292d78",
   "metadata": {},
   "source": [
    "Modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rounds = int(np.median(best_iters))\n",
    "\n",
    "dtrain_full = xgb.DMatrix(\n",
    "    dev_df[feature_cols],\n",
    "    label=dev_df[target_col].values,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "final_booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_full,\n",
    "    num_boost_round=final_rounds,\n",
    "    verbose_eval=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce088684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Métricas en set de prueba (XGB final) ===\n",
      "mae: 135.20 s\n",
      "rmse: 380.71 s\n",
      "sla_le_60s: 59.39%\n",
      "sla_le_120s: 76.00%\n",
      "sla_le_180s: 83.54%\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "# Métricas en set de prueba\n",
    "dtest = xgb.DMatrix(\n",
    "    test_df[feature_cols],\n",
    "    label=test_df[target_col].values,\n",
    "    enable_categorical=True\n",
    ")\n",
    "\n",
    "y_test_pred = final_booster.predict(dtest)\n",
    "\n",
    "test_metrics = compute_metrics(test_df[target_col].values, y_test_pred, SLA_THRESH)\n",
    "print(\"\\n=== Métricas en set de prueba (XGB final) ===\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v*100:.2f}%\" if k.startswith(\"sla_\") else f\"{k}: {v:.2f} s\")\n",
    "    \n",
    "# Guardar el modelo final\n",
    "final_dir = \"D:/2025/UVG/Tesis/repos/backend/models/xgboost/final\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "final_booster.save_model(f\"{final_dir}/xgb_final_model.json\")\n",
    "\n",
    "# Guardar configuración del modelo final\n",
    "final_cfg = final_booster.save_config()\n",
    "with open(f\"{final_dir}/xgb_final_model.config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_cfg)\n",
    "    \n",
    "# Guardar métricas del set de prueba\n",
    "with open(f\"{final_dir}/test_metrics.json\",\"w\") as f:\n",
    "    json.dump({k: float(v) for k, v in test_metrics.items()}, f, indent=2)\n",
    "    \n",
    "# Guardar parámetros y metadatos del modelo final\n",
    "final_meta = {\n",
    "    \"final_rounds\": final_rounds,\n",
    "    \"params\": params,\n",
    "    \"feature_cols\": list(feature_cols),\n",
    "    \"target_col\": target_col\n",
    "}\n",
    "\n",
    "with open(f\"{final_dir}/final_meta.json\",\"w\") as f:\n",
    "    json.dump(final_meta, f, indent=2)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"Fecha\": test_df[\"Fecha\"].values,\n",
    "    \"Placa\": test_df[\"Placa\"].astype(str).values if \"Placa\" in test_df.columns else None,\n",
    "    \"ETA_true\": test_df[target_col].values,\n",
    "    \"ETA_pred\": y_test_pred,\n",
    "    \"abs_error\": np.abs(test_df[target_col].values - y_test_pred)\n",
    "}).to_csv(f\"{final_dir}/test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8a04015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST por LINEA,DIR ===\n",
      "         LINEA       DIR         MAE        RMSE   SLA<=60  SLA<=120  \\\n",
      "5     Linea_12    VUELTA   37.619152   75.194280  0.833992  0.959475   \n",
      "0      Linea_1  CIRCULAR   66.774498  179.904353  0.720273  0.881928   \n",
      "8   Linea_13-A    VUELTA   87.648041  216.681767  0.629023  0.811543   \n",
      "16  Linea_18-B       IDA  117.095230  220.309778  0.566218  0.749646   \n",
      "23     Linea_6    VUELTA  117.506012  326.142499  0.629879  0.793758   \n",
      "19     Linea_2       IDA  120.071205  361.108050  0.508515  0.728775   \n",
      "26     Linea_7    VUELTA  132.928909  377.064215  0.585366  0.783055   \n",
      "7   Linea_13-A       IDA  134.086502  408.652894  0.552213  0.765793   \n",
      "22     Linea_6       IDA  139.582825  369.569746  0.558359  0.742074   \n",
      "20     Linea_2    VUELTA  169.918930  529.769525  0.615599  0.779546   \n",
      "\n",
      "    SLA<=180        n  \n",
      "5   0.984511  42739.0  \n",
      "0   0.932790  33522.0  \n",
      "8   0.889501  13982.0  \n",
      "16  0.825071   2824.0  \n",
      "23  0.858232  15603.0  \n",
      "19  0.853994   7986.0  \n",
      "26  0.865212    779.0  \n",
      "7   0.858473   6981.0  \n",
      "22  0.836706  27031.0  \n",
      "20  0.844011   2513.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pablo Zamora\\AppData\\Local\\Temp\\ipykernel_25508\\3329905506.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  agg = tmp.groupby(by).apply(\n"
     ]
    }
   ],
   "source": [
    "# Desglose por línea\n",
    "def group_report(df, y_true, y_pred, by=[\"LINEA\",\"DIR\"]):\n",
    "    tmp = df.copy()\n",
    "    tmp[\"y_true\"] = y_true\n",
    "    tmp[\"y_pred\"] = y_pred\n",
    "    tmp[\"abs_err\"] = (y_true - y_pred).abs()\n",
    "    agg = tmp.groupby(by).apply(\n",
    "        lambda g: pd.Series({\n",
    "            \"MAE\": g[\"abs_err\"].mean(),\n",
    "            \"RMSE\": (( (g[\"y_true\"]-g[\"y_pred\"])**2 ).mean())**0.5,\n",
    "            \"SLA<=60\": (g[\"abs_err\"]<=60).mean(),\n",
    "            \"SLA<=120\": (g[\"abs_err\"]<=120).mean(),\n",
    "            \"SLA<=180\": (g[\"abs_err\"]<=180).mean(),\n",
    "            \"n\": len(g)\n",
    "        })\n",
    "    ).reset_index()\n",
    "    return agg\n",
    "\n",
    "seg = group_report(test_df, test_df[target_col], y_test_pred, by=[\"LINEA\",\"DIR\"])\n",
    "print(\"\\n=== TEST por LINEA,DIR ===\")\n",
    "print(seg.sort_values(\"MAE\").head(10))\n",
    "seg.to_csv(f\"{final_dir}/test_segment_metrics.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
